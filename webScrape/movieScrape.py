#!/usr/bin/python3

'''
  This program defines functions that can be used to collect data on a movie from a
  given title and date.  The information is collected from imdb and also provides functions
  to retrieve the rotten tomato score and imdb score
'''

from urllib.request import Request, urlopen
import urllib
from urllib.request import urlopen
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.firefox.firefox_binary import FirefoxBinary
from selenium.webdriver.firefox.options import Options
from unidecode import unidecode
import time
import re
import logging
import socket

logging.basicConfig(filename='/var/log/movieScrape/output.log',
                    format='%(asctime)s:%(message)s',
                    level=logging.INFO)
timeout = 120
socket.setdefaulttimeout(timeout)

# This function retrieves a movies url on IMDB using a title with a date year
# It will use IMDB advance search feature and show only movies within the date
# range of plus or minus one year. The movie will be found by searching for a
# link that has the same text as the movie title.
def getIMDBURL(title):
  logging.info(f'Retrieving imdb url for: {title}')
  date = title[-5:-1]
  title = title[:-6]
  if date == '(TBA':
      logging.info(f'{title} has not been released yet. Writing to file and '
                   f'skipping.')
      with open('/var/log/movieScrape/unreleased.log', 'w') as f:
          f.write(f'{title}\n')
      return None
  # This removes the foreign title in parenthesis of any foreign movies
  title = re.sub(r'\([^)]*\)', '', title)
  title = title.replace(' ', '%20')
  url = (f'http://www.imdb.com/search/title?adult=include&release_date='
         f'{str(int(date)-1)},{str(int(date)+1)}&title={title}&'
         f'title_type=feature,short,documentary')
  # For foreign characters in movie title
  url = unidecode(url)
  logging.info(f'Constructed search url for {title}: {url}')
  headers = {"Accept-Language":"en-US,en;q=.5"}
  try:
    req = Request(url, headers = headers)
    title = title.replace('%20', ' ').strip()
    page = urlopen(req)
    soup = BeautifulSoup(page, 'html.parser')
    movie_link = soup.find('a', text = title)
    if movie_link:
      logging.info(f'Page link for {title} found: {movie_link}')
      movie_link = movieLink['href']
      movie_link = movieLink.split('/')[2]
      return movie_link
    else:
      logging.info(f'Page link not found for {title}.')
      return None
  except urllib.error.URLError as e:
    logging.ERROR(f'URLError for {title}. \n URL: {url}')
    logging.ERROR(e)
    with open('/var/log/movieScrape/URLerror.log', 'w') as f:
      f.write(f'{title}: {url}\n')
  except urllib.error.HTTPError as e:
    logging.ERROR(f'HTTPError for {title}. \n URL: {url}')
    logging.ERROR(e)
    with open('/var/log/movieScrape/HTTPError.log', 'w') as f:
          f.write(title + ': HTTPError')

def getBudget(soup):
  budget = soup.find('h4', text = 'Budget:')
  if budget:
    budget = budget.parent.contents[2].strip()
    budget = budget.replace(',','')[1:]
    budget = list(filter(str.isdigit, budget))
    budget = int(''.join(budget))
    return budget
  else:
    return None

def getRevenue(soup):
  gross = soup.find('h4', text = 'Gross:')
  if gross:
    gross = gross.parent.contents[2].strip().replace(',','')[1:]
    return int(gross)
  else:
    return None

# RT rating was challenging because the raw html did not contain the data.
# The data I needed was generated by javascrip after the page was loaded
def getRTRating(title, date):
  logging.INFO(f'Retrieving RT Rating for {title}')
  title.replace(' ', '%20')
  options = Options()
  options.add_argument("--headless")
  binary = FirefoxBinary('/usr/lib/firefox/firefox')
  browser = webdriver.Firefox(firefox_options=options, firefox_binary=binary)
  url = f'https://www.rottentomatoes.com/search/?search={title}'
  try:
    browser.get(url)
    time.sleep(1)
    html = browser.page_source
    browser.quit()
    soup = BeautifulSoup(html, 'lxml')
    results = soup.find('section', id = 'movieSection')
    if not results:
      logging.INFO(f'Could not find RT rating for {title}')
      return None
    results = results.find_all('div', class_ = 'details')
    if not results:
      logging.INFO(f'Could not  find RT rating for {title}')
      return None
    # Search all returned movies on the page and only return the information
    # if the date and title match
    for result in results:
      searchTitle = unidecode(result.span.a.contents[0])
      if not searchTitle:
        logging.INFO(f'Could not find RT rating for {title}')
        return None
      searchDate = result.find('span', class_ = 'movie_year')
      if not searchDate:
        logging.INFO(f'Could not find RT rating for {title}')
        return None
      searchDate = searchDate.contents[4]
      title = title.replace('%20', ' ')
      title = title.strip()
      # If the date plus or minus 1 of search results is within movie date AND
      # the title matches or is within the title then it is a match
      if (((str(searchDate) == date) or
          (str(searchDate) == str(int(date) -1)) or
          (str(searchDate) == str(int(date) + 1))) and
          ((searchTitle.lower()) == title.lower() or (title in searchTitle))):
        rating = result.parent
        rating = rating.find('span', class_ = 'tMeterScore')
        if not rating:
          logging.INFO(f'Could not find RT rating for {title}')
          return None
        rating = rating.contents[1]
        return int(rating)
        break
  except socket.error as socketerror:
    logging.ERROR(f"Timeout for {title}")
    logging.ERROR(socketerror)
    with open('/var/log/movieScrape/timeoutError.log', 'w') as f:
      f.write(f'{title}')

# A function that collects all movie titles and dates on any specific list of
# imdb (like top horror movies)
def getimdbTopList(url):
  page = urlopen(url)
  soup = BeautifulSoup(page, "html.parser")
  titles = soup.find_all('td', class_='titleColumn')
  dates = soup.find_all('span', class_='secondaryInfo')
  ids = soup.find_all('div', class_='wlb_ribbon')
  titleList = []
  dateList = []
  linkList = []
  for i, movies in enumerate(titles):
    titleList.append(movies.a.contents[0])
    dateList.append(str(dates[i].contents[0]))
    linkList.append(ids[i]['data-tconst']);
  return titleList, dateList, linkList

def getimdbList(url, date=None):
  page = urlopen(url)
  soup = BeautifulSoup(page, "html.parser")
  title_headers = soup.find_all('div', class_='lister-item-content')
  titles = []
  links = []
  for title in title_headers:
    movie_title = title.h3.a.contents[0]
    year = title.h3.find('span', class_='lister-item-year').contents[0]
    titles.append(f'{movie_title} {year}')
    links.append(title.div.find('div', class_='ratings-user-rating').span['data-tconst'])
  return titles, links


# A function that gets all movie titles and dates from any given RT list
# (like top 100 movies of 2016)
def getRTList(url):
  print('entered function')
  movieList = []
  page = urlopen(url)
  soup = BeautifulSoup(page, 'html.parser')
  titles = soup.find('table', class_ = 'table').find_all('a')
  for i, movies in enumerate(titles):
    title = str(movies.contents[0])
    title = title.strip()
    movieList.append(title)
  return movieList

# A function that gets all movie titles and dates from any given metacritic list
# (like top thrillers of all time)
def getMetaList(url):
  movieList = []
  req = urllib.request.Request(url, headers={'User-Agent' : "Magic Browser"})
  page = urllib.request.urlopen(req)
  soup = BeautifulSoup(page, 'html.parser')
  titles = soup.find_all('div', class_ = 'title')
  dates = soup.find_all('td', class_ = 'date_wrapper')
  del titles[0]
  for i, movies in enumerate(titles):
    title = movies.a.contents[0]
    date = dates[i].span.contents[0].split(' ')
    print(date)
    date = f'({date[len(date)-1]})'
    title = title + " " + date
    movieList.append(title)
  return movieList
